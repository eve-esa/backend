generation:
  model_id: mistralai/Mistral-7B-Instruct-v0.2
  max_new_tokens: 2000
  temperature: 0.7
  top_p: 0.9

hallucination_detection:
  model_id: mistralai/Mistral-7B-Instruct-v0.2
  max_new_tokens: 256
  temperature: 0.5
  top_p: 0.95

reprompting:
  model_id: mistralai/Mistral-7B-Instruct-v0.2
  max_new_tokens: 128
  temperature: 0.8
  top_p: 0.9

reflection:
  model_id: mistralai/Mistral-7B-Instruct-v0.2
  max_new_tokens: 256
  temperature: 0.6
  top_p: 0.9
